{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.terminal = None\n",
    "        self.children = dict()\n",
    "    \n",
    "class BOR:\n",
    "    def __init__(self):\n",
    "        self.root = Node()\n",
    "    \n",
    "    def b_insert(self, word, cur_node):\n",
    "        for symb in word:\n",
    "            if symb not in cur_node.children:\n",
    "                cur_node.children[symb] = Node()\n",
    "            cur_node = cur_node.children[symb]\n",
    "        \n",
    "        cur_node.terminal = word\n",
    "    \n",
    "    def insert(self, word):\n",
    "        self.b_insert(word, self.root)\n",
    "    \n",
    "    def b_nearest_words(self, cur_node, word, max_dist, prev_lev, symb, res):\n",
    "        n2 = len(word) + 1\n",
    "        lev = []\n",
    "        \n",
    "        lev.append(prev_lev[0] + 1)\n",
    "        \n",
    "        for j in range(1, n2):\n",
    "            var1 = lev[j-1]+1\n",
    "            var2 = prev_lev[j]+1\n",
    "            var3 = prev_lev[j-1]\n",
    "            if symb != word[j-1]:\n",
    "                var3 += 1\n",
    "            lev.append(min(var1, var2, var3))\n",
    "            \n",
    "        if cur_node.terminal is not None and lev[n2-1] <= max_dist:\n",
    "            res.append([cur_node.terminal, lev[n2-1]])\n",
    "            \n",
    "        flag = False\n",
    "        for elt in lev:\n",
    "            if elt <= max_dist:\n",
    "                flag = True\n",
    "                break\n",
    "            \n",
    "        if flag:\n",
    "            for symb in cur_node.children:\n",
    "                self.b_nearest_words(cur_node.children[symb], word, max_dist, lev, symb, res)\n",
    "                \n",
    "    def nearest_words(self, word, max_dist):\n",
    "        n1 = len(word)+1\n",
    "        lev = []\n",
    "        for i in range(n1):\n",
    "            lev.append(i)\n",
    "        res = []\n",
    "        for symb in self.root.children:\n",
    "            self.b_nearest_words(self.root.children[symb], word, max_dist, lev, symb, res)\n",
    "        return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorModel():\n",
    "    \n",
    "    def __init__(self, alpha = 0.5):\n",
    "        self.alpha = alpha\n",
    "        self.tree = BOR()\n",
    "        \n",
    "    def add_to_bor(self, word):\n",
    "        self.tree.insert(word)\n",
    "        \n",
    "    def lev_dist(s1, s2):\n",
    "        n1 = len(s1)+1\n",
    "        n2 = len(s2)+1\n",
    "        lev = []\n",
    "        for i in range(n1):\n",
    "            lev.append([0]*n2)\n",
    "        for i in range(1, n1):\n",
    "            lev[i][0] = i\n",
    "        for i in range(1, n2):\n",
    "            lev[0][i] = i\n",
    "        for i in range(1, n1):\n",
    "            for j in range(1, n2):\n",
    "                var1 = lev[i-1][j]+1\n",
    "                var2 = lev[i][j-1]+1\n",
    "                var3 = lev[i-1][j-1]\n",
    "                if s1[i-1] != s2[j-1]:\n",
    "                    var3 += 1\n",
    "                lev[i][j] = min(var1, var2, var3)\n",
    "        return lev[n1-1][n2-1]\n",
    "    \n",
    "    def get_nearest(self, word, max_dist):\n",
    "        nearest = self.tree.nearest_words(word, max_dist)\n",
    "        res = []\n",
    "        for elt in nearest:\n",
    "            res.append([elt[0], self.alpha ** (-elt[1])])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stat = dict()\n",
    "        self.stat2 = dict()\n",
    "        self.size = 0\n",
    "        self.size2 = 0\n",
    "        self.Dict = set()\n",
    "        \n",
    "    def add_to_dict(self, word):\n",
    "        self.Dict.add(word)\n",
    "    \n",
    "    def isin(self, word):\n",
    "        return word in Dict\n",
    "        \n",
    "    def add_to_stat(self, word):\n",
    "        self.size += 1\n",
    "        if word in self.stat:\n",
    "            self.stat[word] += 1\n",
    "        else:\n",
    "            self.stat[word] = 1\n",
    "            \n",
    "    def add_to_stat2(self, word):\n",
    "        self.size2 += 1\n",
    "        if word in self.stat2:\n",
    "            self.stat2[word] += 1\n",
    "        else:\n",
    "            self.stat2[word] = 1\n",
    "    \n",
    "    def to_bigram(self, words):\n",
    "        res = []\n",
    "        for i in range(1, len(words)):\n",
    "            bigram = words[i-1] + words[i]\n",
    "            res.append(bigram)\n",
    "        return res\n",
    "    \n",
    "    def get_freq_query(self, words):\n",
    "        p = 1\n",
    "        for word in words:\n",
    "            if word in self.stat:\n",
    "                p *= self.stat[word]/self.size\n",
    "        return p\n",
    "    \n",
    "    def get_freq_query2(self, words):\n",
    "        p = 1\n",
    "        for i in range(1, len(words)):\n",
    "            bigram = words[i-1] + words[i]\n",
    "            if bigram in self.stat2:\n",
    "                p *= self.stat2[bigram]/self.size2\n",
    "        return p\n",
    "    \n",
    "    def get_frequency_word(self, word):\n",
    "        if word in self.stat:\n",
    "            return self.stat[word]/self.size\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def delete_rare_words(self, split):\n",
    "        for key in self.stat:\n",
    "            if get_frequency(key) < split:\n",
    "                self.stat.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(words):\n",
    "    length = 0\n",
    "    for elt in words:\n",
    "        length += len(elt)\n",
    "    k_words = len(words)\n",
    "    if k_words > 1:\n",
    "        freq = LangModel.get_freq_query2(words)\n",
    "    else:\n",
    "        freq = LangModel.get_freq_query(words)\n",
    "    \n",
    "    in_dict = 0\n",
    "    max_p = 0\n",
    "    min_p = 1\n",
    "    \n",
    "    for word in words:\n",
    "        if word in Dict:\n",
    "            in_dict += 1\n",
    "        p = LangModel.get_frequency_word(word)\n",
    "        min_p = min(p, min_p)\n",
    "        max_p = max(p, max_p)\n",
    "    \n",
    "    not_in_dict = k_words - in_dict\n",
    "    \n",
    "    return [length, k_words, not_in_dict, max_p, min_p, freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_before_tab(s):\n",
    "    return s[:s.find('\\t')]\n",
    "\n",
    "def get_after_tab(s):\n",
    "    return s[s.find('\\t')+1:]\n",
    "\n",
    "f = open('queries_all.txt', 'r')\n",
    "#spec = ' ?!(),.+'\n",
    "spec = ' '\n",
    "\n",
    "ErrModel = ErrorModel(2)\n",
    "LangModel = LanguageModel()\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for line in f:\n",
    "    if line[-1] == '\\n':\n",
    "        line = line[:-1]\n",
    "    orig = get_before_tab(line)\n",
    "    fix = get_after_tab(line)\n",
    "    words = fix.split(spec)\n",
    "    #words = [re.sub(r'[^A-zА-я0-9]', '', word) for word in words] \n",
    "    if fix != \"\":\n",
    "        for word in words:\n",
    "            LangModel.add_to_stat(word) \n",
    "            LangModel.add_to_dict(word)\n",
    "            ErrModel.add_to_bor(word)\n",
    "        bi_words = LangModel.to_bigram(words)\n",
    "        if bi_words:\n",
    "            for word in bi_words:\n",
    "                LangModel.add_to_stat2(word)\n",
    "        train_x.append(get_features(words))\n",
    "        train_y.append(1)\n",
    "        train_x.append(get_features(orig.split(spec)))\n",
    "        train_y.append(0)\n",
    "    else:\n",
    "        train_x.append(get_features(orig.split(spec)))\n",
    "        train_y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8871379693735069"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "size = 300000\n",
    "subtrain_x = train_x[:size]\n",
    "subtrain_y = train_y[:size]\n",
    "\n",
    "subtest_x = train_x[size:]\n",
    "subtest_y = train_y[size:]\n",
    "\n",
    "#clf = GradientBoostingClassifier()\n",
    "clf = LGBMClassifier()\n",
    "clf.fit(subtrain_x, subtrain_y)\n",
    "pred = clf.predict(subtest_x)\n",
    "f1_score(pred, subtest_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "clf = LGBMClassifier()\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "rus2eng = {'й': 'q', 'ц': 'w', 'у': 'e', 'к': 'r', 'е': 't', 'н': 'y', 'г': 'u', 'ш': 'i', 'щ': 'o', 'з': 'p', 'х': '[', 'ъ': ']', \n",
    "           'ф': 'a', 'ы': 's', 'в': 'd', 'а': 'f', 'п': 'g', 'р': 'h', 'о': 'j', 'л': 'k', 'д': 'l', 'ж': ';', 'э': \"'\", \n",
    "           'я': 'z', 'ч': 'x', 'с': 'c', 'м': 'v', 'и': 'b', 'т': 'n', 'ь': 'm', 'б': ',', 'ю': '.' }\n",
    "eng2rus = {'q': 'й', 'w': 'ц', 'e': 'у', 'r': 'к', 't': 'е', 'y': 'н', 'u': 'г', 'i': 'ш', 'o': 'щ', 'p': 'з', '[': 'х', ']': 'ъ', \n",
    "           'a': 'ф', 's': 'ы', 'd': 'в', 'f': 'а', 'g': 'п', 'h': 'р', 'j': 'о', 'k': 'л', 'l': 'д', ';': 'ж', \"'\": 'э', \n",
    "           'z': 'я', 'x': 'ч', 'c': 'с', 'v': 'м', 'b': 'и', 'n': 'т', 'm': 'ь', ',': 'б', '.': 'ю' }\n",
    "\n",
    "def change_keyboard(words):\n",
    "    res = []\n",
    "    for word in words:\n",
    "        changed = \"\"\n",
    "        for symb in word:\n",
    "            if symb in rus2eng:\n",
    "                changed += rus2eng[symb]\n",
    "            elif symb in eng2rus:\n",
    "                changed += eng2rus[symb]\n",
    "            else:\n",
    "                changed += symb\n",
    "        res.append(changed)\n",
    "    return res\n",
    "\n",
    "def change_split(words):\n",
    "    res = []\n",
    "    num = 0\n",
    "    for word in words:\n",
    "        if not LangModel.isin(word):\n",
    "            for ind in range(1, len(word)-1):\n",
    "                split = []\n",
    "                split.extend(words[:num])\n",
    "                split.append(word[0:ind])\n",
    "                split.append(word[ind:])\n",
    "                split.extend(words[num+1:])\n",
    "                res.append(split)\n",
    "        num += 1\n",
    "    return res\n",
    "\n",
    "def get_corrections(words):\n",
    "    res = []\n",
    "    for word in words:\n",
    "        if LangModel.isin(word):\n",
    "            res.append([word])\n",
    "        else:\n",
    "            nearest = ErrModel.get_nearest(word, 1)\n",
    "            res.append([])\n",
    "            if len(nearest) > 0:\n",
    "                for w, value in nearest:\n",
    "                    res[-1].append(w)\n",
    "            else:\n",
    "                res[-1].append(word)\n",
    "    return product(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "привет\n",
      "привет\n",
      "прувет\n",
      "привет\n",
      "превет\n",
      "привет\n",
      "прувет как дила\n",
      "прувер как дила\n",
      "привет как дело\n",
      "ghbdtn rfr lkj\n",
      "ghbdtn\n",
      "привет\n",
      "приветик\n",
      "приветик\n",
      "купить машину\n",
      "купить машину\n",
      "купить машыну\n",
      "купить машыну\n",
      "купить машына\n",
      "купить машина\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-7d2f23c059bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "k_iter = 2\n",
    "\n",
    "while True:\n",
    "    %timeit\n",
    "    query = input()\n",
    "    if query[-1] == '\\n':\n",
    "        query = query[:-1]\n",
    "    words = query.split(spec)\n",
    "    features = [get_features(words)]\n",
    "    if clf.predict(features) == 1:\n",
    "        print(query)\n",
    "    else:\n",
    "        flag = False\n",
    "        for i in range(k_iter):\n",
    "            variants = []\n",
    "            features = []\n",
    "            prob = []\n",
    "            \n",
    "            arr = get_corrections(words)\n",
    "            for q in arr:\n",
    "                variants.append(list(q))\n",
    "                features.append(get_features(q))\n",
    "                prob.append(LangModel.get_freq_query2(q))\n",
    "            \n",
    "            arr = change_keyboard(words)\n",
    "            variants.append(arr)\n",
    "            features.append(get_features(arr))\n",
    "            prob.append(LangModel.get_freq_query2(arr))\n",
    "            \n",
    "            arr = change_split(words)\n",
    "            if len(arr) != 0:\n",
    "                #variants.extend(arr)\n",
    "                for q in arr:\n",
    "                    variants.append(q)\n",
    "                    features.append(get_features(q))\n",
    "                    prob.append(LangModel.get_freq_query2(q))\n",
    "            max_freq = -1\n",
    "            num = -1\n",
    "            all_max_freq = -1\n",
    "            all_num = -1\n",
    "            for i in range(len(variants)):\n",
    "                if clf.predict([features[i]]) == 1:\n",
    "                    if prob[i] > max_freq:\n",
    "                        max_freq = prob[i]\n",
    "                        num = i\n",
    "                if prob[i] > all_max_freq:\n",
    "                    all_max_freq = prob[i]\n",
    "                    all_num = i\n",
    "            if num != -1:\n",
    "                print(' '.join(variants[num]))\n",
    "                flag = True\n",
    "                break\n",
    "            else:\n",
    "                words = variants[all_num]\n",
    "                \n",
    "        if not flag:\n",
    "            print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def load(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(clf, 'objects/Classificator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "save(ErrModel, 'objects/ErrorModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-e6e7eee5239c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLangModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'objects/LanguageModel.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-b74e5f71a8cd>\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save(LangModel, 'objects/LanguageModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
